{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regulariser_unit_tests.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ZacCranko/robustlearningexperiments/blob/master/regulariser_unit_tests.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "xdqW-kE8Srje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 Google LLC and Zac Cranko\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RjNQMY67tiSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 Google LLC.\n",
        "# SPDX-License-Identifier: Apache-2.0\n",
        "def power_iterate_conv(layer, num_iter):\n",
        "  \"\"\"Perform power iteration for a convolutional layer.\"\"\"\n",
        "  assert isinstance(layer, tf.keras.layers.Conv2D)\n",
        "  weights = layer.kernel\n",
        "  strides = (1,) + layer.strides + (1,)\n",
        "  padding = layer.padding.upper()\n",
        "  \n",
        "  with tf.variable_scope(None, default_name='power_iteration'):\n",
        "    u_var = tf.get_variable(\n",
        "       'u_conv', [1] + map(int, layer.output_shape[1:]),\n",
        "       initializer=tf.random_normal_initializer(),\n",
        "       trainable=False)\n",
        "    u = u_var\n",
        "    \n",
        "    for _ in xrange(num_iter):\n",
        "      v = tf.nn.conv2d_transpose(\n",
        "         u, weights, [1] + map(int, layer.input_shape[1:]), strides, padding)\n",
        "      v /= tf.sqrt(tf.maximum(2 * tf.nn.l2_loss(v), 1e-12))\n",
        "      u = tf.nn.conv2d(v, weights, strides, padding)\n",
        "      u /= tf.sqrt(tf.maximum(2 * tf.nn.l2_loss(u), 1e-12))\n",
        "      \n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tf.assign(u_var, u))\n",
        "\n",
        "    u = tf.stop_gradient(u)\n",
        "    v = tf.stop_gradient(v)\n",
        "    return tf.reduce_sum(u * tf.nn.conv2d(v, weights, strides, padding))\n",
        "  \n",
        "def power_iterate_dense(layer, num_iter):\n",
        "  \"\"\"Perform power iteration for a fully connected layer.\"\"\"\n",
        "  assert isinstance(layer, tf.keras.layers.Dense)\n",
        "  weights = layer.kernel\n",
        "  output_shape, input_shape = weights.get_shape().as_list()\n",
        "\n",
        "  with tf.variable_scope(None, default_name='power_iteration'):\n",
        "    u_var = tf.get_variable(\n",
        "       'u',  map(int, [output_shape]) + [1],\n",
        "       initializer=tf.random_normal_initializer(),\n",
        "       trainable=False)\n",
        "    u = u_var\n",
        "\n",
        "    for _ in xrange(num_iter):\n",
        "      v = tf.matmul(weights, u, transpose_a=True)\n",
        "      v /= tf.sqrt(tf.maximum(2 * tf.nn.l2_loss(v), 1e-12))\n",
        "      u = tf.matmul(weights, v)\n",
        "      u /= tf.sqrt(tf.maximum(2 * tf.nn.l2_loss(u), 1e-12))\n",
        "\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tf.assign(u_var, u))\n",
        "\n",
        "    u = tf.stop_gradient(u)\n",
        "    v = tf.stop_gradient(v)\n",
        "    return tf.reduce_sum(u * tf.matmul(weights, v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4l9ZdjxfG4tY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def operator_norm(layer, ord = 2, **kwargs):\n",
        "    \"\"\"Compute operator norm for a Keras layer.\"\"\"\n",
        "    \n",
        "    with tf.variable_scope(None, default_name='operator_norm'):\n",
        "      if ord == 1:\n",
        "          w = layer.kernel\n",
        "          if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "              sum_w = tf.reduce_sum(tf.abs(w), [0, 1, 3])\n",
        "          else:\n",
        "              sum_w = tf.reduce_sum(tf.abs(w), 1)\n",
        "\n",
        "          return tf.reduce_max(sum_w)\n",
        "\n",
        "      elif ord == 2:\n",
        "          num_iter = kwargs.get('num_iter', 5)\n",
        "          if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "              return power_iterate_conv(layer, num_iter)\n",
        "          else:\n",
        "              return power_iterate_dense(layer, num_iter)\n",
        "\n",
        "      elif ord == np.inf:\n",
        "          w = layer.kernel\n",
        "          if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "              sum_w = tf.reduce_sum(tf.abs(w), [0, 1, 2])\n",
        "          else:\n",
        "              sum_w = tf.reduce_sum(tf.abs(w), 0)\n",
        "\n",
        "          return tf.reduce_max(sum_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24NAhjHvS5fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tf_assert_almost_equal(actual, desired, **kwargs):\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    _actual  = actual.eval()\n",
        "    _desired = desired.eval()\n",
        "\n",
        "  return np.testing.assert_almost_equal(_actual, _desired, **kwargs)\n",
        "\n",
        "def conv_matrix(layer):\n",
        "  \"\"\"Build the matrix associated with the convolution operation.\"\"\"\n",
        "  assert isinstance(layer, tf.keras.layers.Conv2D)\n",
        "  with tf.variable_scope(None, default_name='build_conv_matrix'):\n",
        "    weights = layer.kernel\n",
        "    strides = (1,) + layer.strides + (1,)\n",
        "    padding = layer.padding.upper()\n",
        "    in_h,  in_w,  in_ch  = layer.input_shape[1:4]\n",
        "    out_h, out_w, out_ch = layer.output_shape[1:4]\n",
        "\n",
        "    id_mx     = tf.reshape(tf.eye(in_h*in_w*in_ch), \n",
        "                            (in_h*in_w*in_ch, in_h, in_w, in_ch))\n",
        "    conv_mx_t = tf.reshape(tf.nn.conv2d(id_mx, weights, strides, padding), \n",
        "                            (in_h*in_w*in_ch, out_h*out_w*out_ch))\n",
        "    return tf.transpose(conv_mx_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7sA-821-rV4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "conv1 = tf.keras.layers.Conv2D(32, 5, 1, padding='SAME',\n",
        "                               input_shape=(28, 28, 1))\n",
        "model.add(conv1)\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2, 2, padding='SAME'))\n",
        "\n",
        "conv2 = tf.keras.layers.Conv2D(64, 5, 1, padding='SAME')\n",
        "model.add(conv2)\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(1024)\n",
        "model.add(dense1)\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "dense2 = tf.keras.layers.Dense(10)\n",
        "model.add(dense2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyXDyXml4MI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_iter = 200\n",
        "\n",
        "# test dense layers\n",
        "for layer in ['dense1', 'dense2']:\n",
        "  _layer = eval(layer)\n",
        "  \n",
        "  op = \"1_norm\"\n",
        "  # axis = 1 here since _layer.kernel is stored transposed for dense layers\n",
        "  inf_opn_mx = tf.reduce_max(tf.reduce_sum(tf.abs(_layer.kernel), axis = 1))\n",
        "  tf_assert_almost_equal(operator_norm(_layer, 1), inf_opn_mx, err_msg = \"%s(%s)\"%(op,layer), decimal = 1)\n",
        "  \n",
        "  op = \"inf_norm\"\n",
        "  # axis = 0 here since _layer.kernel is stored transposed for dense layers\n",
        "  inf_opn_mx = tf.reduce_max(tf.reduce_sum(tf.abs(_layer.kernel), axis = 0))\n",
        "  tf_assert_almost_equal(operator_norm(_layer, np.inf), inf_opn_mx, err_msg = \"%s(%s)\"%(op,layer), decimal = 1)\n",
        "  \n",
        "  op = \"spectral_norm\"\n",
        "  spec_pow  = operator_norm(_layer, 2, num_iter = num_iter)\n",
        "  spec_svd  = tf.svd(_layer.kernel, compute_uv=False)\n",
        "  tf_assert_almost_equal(spec_pow, spec_svd[0], decimal = 2, err_msg = \"%s(%s)\"%(op,layer))\n",
        "\n",
        "# test conv layers\n",
        "for layer in ['conv1', 'conv2']:\n",
        "  _layer = eval(layer)\n",
        "  \n",
        "  op = \"1_norm\"\n",
        "  conv_mx = conv_matrix(_layer)\n",
        "  desired = tf.reduce_max(tf.reduce_sum(tf.abs(conv_mx), axis = 0))\n",
        "  tf_assert_almost_equal(operator_norm(_layer, 1), desired, err_msg = \"%s(%s)\"%(op,layer), decimal = 1)\n",
        "  \n",
        "  op = \"inf_norm\"\n",
        "  conv_mx = conv_matrix(_layer)\n",
        "  desired = tf.reduce_max(tf.reduce_sum(tf.abs(conv_mx), axis = 1))\n",
        "  tf_assert_almost_equal(operator_norm(_layer, np.inf), desired, err_msg = \"%s(%s)\"%(op,layer), decimal = 1)\n",
        "  \n",
        "  op = \"spectral_norm\"\n",
        "  spec_pow  = operator_norm(_layer, 2, num_iter = num_iter)\n",
        "  spec_svd  = tf.svd(conv_matrix(_layer), compute_uv=False)\n",
        "  tf_assert_almost_equal(spec_pow, spec_svd[0], err_msg = \"%s(%s)\"%(op,layer), decimal = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}